{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "ebff0219-4a8b-4559-bb87-ff253af74173"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uria\\vmplayer_shared\\Pnml_code\\deep_pnml\\src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd()) #print working dir\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import time\n",
    "import json\n",
    "from analyze_utilities import *\n",
    "from dataset_utilities import create_cifar10_dataloaders\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./result_summary_uriya.ipynb\n",
    "print(files_nml_2_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../output/figures'\n",
    "is_plot_title = False\n",
    "is_save_fig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)\n",
    "print(plt.rcParams)\n",
    "plt.style.use(['seaborn-darkgrid', 'seaborn-paper'])\n",
    "label_size = 16\n",
    "tick_size = 14\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('axes', titlesize=label_size)\n",
    "plt.rc('axes', labelsize=label_size)\n",
    "plt.rc('xtick', labelsize=tick_size)\n",
    "plt.rc('ytick', labelsize=tick_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "24ca4ce8-ea48-4093-bb82-aa9fb8c95eba"
    }
   },
   "source": [
    "# PNML Vs. ERM Performence\n",
    "PNML is as training is as following:\n",
    "1. Train base model with all trainset\n",
    "2. Freeze first layers (only enable updates of layer 5,6 in resnet20)\n",
    "3. For each test sample:\n",
    "    1. For each label:\n",
    "        1. Add the test sample with the label to trainset\n",
    "        2. Train for 10 epochs the model\n",
    "        3. Keep probability of the test sample label which it was trained with\n",
    "    2. Take all save probabilities and normalize them.\n",
    "    3. Report the new probability assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paths for pnml training...\n",
      "loading paths for Twice universality with FGSM...\n",
      "['./../results/deep_net/twice_univ/M23/results_mnist_adversarial_20190416_165303.json']\n",
      "                 genie\n",
      "acc           0.970000\n",
      "mean loss     0.125149\n",
      "std loss      0.436416\n",
      "mean entropy  0.102497\n",
      "100\n",
      "                   erm\n",
      "acc           0.950000\n",
      "mean loss     0.238443\n",
      "std loss      0.817213\n",
      "mean entropy  0.117349\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "%run ./result_summary_uriya.ipynb\n",
    "print(M23_path)\n",
    "calc_erm_and_genie_stats(M11_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_df: loaded in 4.33 [s]\n",
      "          acc  mean loss  std loss  mean entropy\n",
      "nml    0.9716   0.095734  0.535681      0.039858\n",
      "erm    0.9710   0.089637  0.480922      0.038878\n",
      "genie  0.9481   0.156390  0.657725      0.054662\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Print acc and mean loss\n",
    "tic = time.time()\n",
    "result_df, statistics_df = load_results_to_df(mnist_fgsm_natural_fgsm_all)\n",
    "print('result_df: loaded in {0:.2f} [s]'.format(time.time() - tic))\n",
    "print(statistics_df.transpose())\n",
    "print(result_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Loss vs sample index graph\n",
    "ii = list(range(0,50)) # index range to display\n",
    "\n",
    "\n",
    "\n",
    "result_df1, statistics_df = load_results_to_df(M14_path)\n",
    "result_df2, statistics_df = load_results_to_df(M24_path)\n",
    "result_df1 = result_df1.sort_index(axis=0)\n",
    "result_df2 = result_df2.sort_index(axis=0)\n",
    "print(result_df1.index[ii])\n",
    "fig=plt.figure(figsize=(14, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "s1 = plt.scatter(result_df1.index[ii], result_df1['nml_loss'][ii], c=\"red\")\n",
    "s2 = plt.scatter(result_df2.index[ii], result_df2['nml_loss'][ii], c=\"blue\")\n",
    "plt.xlabel('Test sample Index')\n",
    "plt.ylabel('Log-loss')\n",
    "plt.legend((s1, s2),\n",
    "           ('M1 (eps=0.25)', 'M2 (eps=0.1)'),\n",
    "           scatterpoints=1,\n",
    "           loc='upper right',\n",
    "           ncol=1,\n",
    "           fontsize=10)\n",
    "plt.title('Log-Loss per sample for eps=0.25 attack')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7b07e771-2023-4886-9b02-70723d626a48"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regret histogram\n",
    "bins = 100\n",
    "plt.hist(result_df['log10_norm_factor'], density=True,\n",
    "         label='pNML', bins=bins, color='darkorange')\n",
    "plt.xlim([-0.0001, 1])\n",
    "plt.title('Regret Histogram') if is_plot_title else None\n",
    "plt.xlabel('Regret')\n",
    "plt.ylabel('Density')\n",
    "# plt.savefig(os.path.join(output_path, 'regret_hist.jpg'), dpi=200,\n",
    "#             bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()\n",
    "\n",
    "# logloss histogram\n",
    "bins = 100\n",
    "plt.hist(result_df['nml_loss'], bins=bins, alpha=0.8,\n",
    "         label='pNML', density=True, color='darkorange')\n",
    "plt.hist(result_df['erm_loss'], bins=bins,\n",
    "         alpha=0.6, label='ERM', density=True)\n",
    "plt.title('Logloss Histogram') if is_plot_title else None\n",
    "plt.xlabel('Log-loss')\n",
    "plt.ylabel('Density')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=0)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_path, 'logloss_hist.jpg'), dpi=200,\n",
    "            bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = list(result_df['log10_norm_factor'])\n",
    "y_data = list(result_df['nml_loss'])\n",
    "g = sns.JointGrid(x=x_data,  y=y_data)\n",
    "g.plot_marginals(sns.kdeplot, shade=True, color='red')\n",
    "g.plot_joint(plt.hist2d, bins=[100, 100], norm=mpl.colors.SymLogNorm(0.1),\n",
    "             cmin=1, cmap=plt.cm.Reds)\n",
    "g.ax_joint.grid(True)\n",
    "g.ax_joint.set_ylabel('Log-loss', fontsize=label_size-4)\n",
    "g.ax_joint.set_xlabel('Regret', fontsize=label_size-4)\n",
    "\n",
    "# make new ax object for the cbar\n",
    "plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "cbar_ax = g.fig.add_axes([.82, 0.2, .03, .5])  # x, y, width, height\n",
    "plt.colorbar(cax=cbar_ax).set_label(label='Count', fontsize=label_size-4)\n",
    "cbar_ax.tick_params(labelsize=10)\n",
    "plt.savefig(os.path.join(output_path, 'loss_vs_regret_jointplot.jpg'), dpi=200,\n",
    "            bbox_inches='tight',  bbox_extra_artists=(cbar_ax,),) if is_save_fig else None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = 5\n",
    "\n",
    "x_data = list(result_df['log10_norm_factor'][::subsample])\n",
    "y_data = list(result_df['nml_loss'][::subsample])\n",
    "g = sns.JointGrid(x=x_data,  y=y_data,  xlim=(0, 0.8), ylim=(0,14))\n",
    "g.plot_marginals(sns.kdeplot, shade=True, color='orange')\n",
    "g.plot_joint(plt.scatter, c='orange',  edgecolor=\"white\", label='pNML', s=10)\n",
    "# add scatter of erm\n",
    "g.x = result_df['log10_norm_factor'][::subsample]\n",
    "g.y = result_df['erm_loss'][::subsample]\n",
    "g.plot_joint(plt.scatter, c='C0', label='ERM', s=10)\n",
    "\n",
    "g.ax_joint.grid(True)\n",
    "g.ax_joint.set_ylabel('Log-loss', fontsize=label_size-2)\n",
    "g.ax_joint.set_xlabel('Regret', fontsize=label_size-2)\n",
    "\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.savefig(os.path.join(output_path, 'loss_vs_regret_jointplot_scatter.jpg'), dpi=200,\n",
    "            bbox_inches='tight',  bbox_extra_artists=(cbar_ax,),) if is_save_fig else None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot histogram of correct vs incorrect\n",
    "correct_norm_factor = result_df['log10_norm_factor'][result_df['nml_is_correct'] == True]\n",
    "incorrect_norm_factor = result_df['log10_norm_factor'][result_df['nml_is_correct'] == False]\n",
    "\n",
    "bins = 20\n",
    "\n",
    "plt.hist(correct_norm_factor, alpha=1, bins=bins,\n",
    "         density=True, color='blue', label='Correct')\n",
    "plt.hist(incorrect_norm_factor, alpha=0.5, bins=bins,\n",
    "         density=True, color='red', label='Incorrect')\n",
    "plt.title(\n",
    "    'Regret Histogram with Correct and Incorrect Separation') if is_plot_title else None\n",
    "plt.xlabel('Regret')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_path, 'correct_incorrect_hist.jpg'), dpi=200,\n",
    "            bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('Correct = %d, Incorrect = %d ' %\n",
    "      (correct_norm_factor.shape[0], incorrect_norm_factor.shape[0]))\n",
    "print('Mean [correct, incorrect]={}'.format(\n",
    "    [correct_norm_factor.mean(), incorrect_norm_factor.mean()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose Regret based Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Construct best loss based on normalization factor\n",
    "threshold_list = np.linspace(np.finfo(float).eps, 1, 99)\n",
    "acc_list = []\n",
    "acc_erm_list = []\n",
    "cdf_list = []\n",
    "nml_thresh_loss_list = []\n",
    "erm_thresh_loss_list = []\n",
    "for threshold in threshold_list:\n",
    "    df = result_df[result_df['log10_norm_factor'] < threshold]\n",
    "\n",
    "    # loss\n",
    "    nml_thresh_loss_list.append(df['nml_loss'].mean())\n",
    "    erm_thresh_loss_list.append(df['erm_loss'].mean())\n",
    "\n",
    "    # Acc\n",
    "    acc_single = np.sum(df['nml_is_correct'] == True) / \\\n",
    "        (df.shape[0] + np.finfo(float).eps)\n",
    "    acc_list.append(acc_single)\n",
    "    acc_erm_single = np.sum(df['erm_is_correct'] == True) / \\\n",
    "        (df.shape[0] + np.finfo(float).eps)\n",
    "    acc_erm_list.append(acc_erm_single)\n",
    "\n",
    "    cdf_single = df.shape[0] / result_df.shape[0]\n",
    "    cdf_list.append(cdf_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gridspec.GridSpec(3, 1)\n",
    "# Acc\n",
    "acc_color = 'royalblue'\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.plot(threshold_list, acc_list)\n",
    "ax1.set_ylabel('Acc.')\n",
    "\n",
    "labels = [item.get_text() for item in ax1.get_xticklabels()]\n",
    "empty_string_labels = [''] * len(labels)\n",
    "ax1.set_xticklabels(empty_string_labels)\n",
    "\n",
    "# Loss\n",
    "loss_color = 'green'\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.plot(threshold_list, nml_thresh_loss_list)\n",
    "ax2.set_ylabel('Log-loss')\n",
    "labels = [item.get_text() for item in ax2.get_xticklabels()]\n",
    "empty_string_labels = [''] * len(labels)\n",
    "ax2.set_xticklabels(empty_string_labels)\n",
    "\n",
    "# CDF\n",
    "ax3 = plt.subplot(gs[2])\n",
    "ax3.plot(threshold_list, cdf_list)\n",
    "ax3.set_yticks(np.linspace(0, 1, 6))\n",
    "ax3.set_xlabel('Regret threshold')\n",
    "ax3.set_ylabel('CDF')\n",
    "\n",
    "# Save and show\n",
    "plt.savefig(os.path.join(output_path, 'regret_based_calss_all.jpg'),\n",
    "            dpi=200, bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gs = gridspec.GridSpec(3, 1)\n",
    "# Acc\n",
    "acc_color = 'royalblue'\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.plot(threshold_list, acc_erm_list, '-*' , label='ERM', color='C0')\n",
    "ax1.plot(threshold_list, acc_list, label='pNML', color='orange')\n",
    "ax1.set_ylabel('Acc.')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "labels = [item.get_text() for item in ax1.get_xticklabels()]\n",
    "empty_string_labels = [''] * len(labels)\n",
    "ax1.set_xticklabels(empty_string_labels)\n",
    "\n",
    "# Loss\n",
    "loss_color = 'green'\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.plot(threshold_list, erm_thresh_loss_list, '-*' , label='ERM', color='C0')\n",
    "ax2.plot(threshold_list, nml_thresh_loss_list, label='pNML', color='orange')\n",
    "ax2.set_ylabel('Log-loss')\n",
    "labels = [item.get_text() for item in ax2.get_xticklabels()]\n",
    "empty_string_labels = [''] * len(labels)\n",
    "ax2.set_xticklabels(empty_string_labels)\n",
    "\n",
    "# CDF\n",
    "ax3 = plt.subplot(gs[2])\n",
    "ax3.plot(threshold_list, cdf_list, color='orange')\n",
    "ax3.set_yticks(np.linspace(0, 1, 6))\n",
    "ax3.set_xlabel('Regret threshold')\n",
    "ax3.set_ylabel('CDF')\n",
    "\n",
    "# Save and show\n",
    "plt.savefig(os.path.join(output_path, 'regret_based_class_all_with_erm.jpg'),\n",
    "            dpi=200, bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({'CDF': cdf_list, 'Regret thresh': threshold_list, 'acc': acc_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out  of Disterbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load svhn and noise\n",
    "results_df_cifar10, statistic_cifar10 = load_results_to_df(files_nml_2_layers)\n",
    "print('Cifar10: loaded %d keys' % results_df_cifar10.shape[0])\n",
    "results_df_noise, statistic_noise = load_results_to_df(\n",
    "    files_noise, is_out_of_dist=True)\n",
    "print('Noise: loaded %d keys' % results_df_noise.shape[0])\n",
    "results_df_svhn, statistic_svhn = load_results_to_df(\n",
    "    files_svhn, is_out_of_dist=True)\n",
    "print('SVHN: loaded %d keys' % results_df_svhn.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "bins = 20\n",
    "plt.hist(results_df_cifar10['log10_norm_factor'], alpha=1, density=True, label='CIFAR10', bins=bins)\n",
    "plt.hist(results_df_svhn['log10_norm_factor'], alpha=0.5, density=True, label='SVHN', bins=bins)\n",
    "plt.hist(results_df_noise['log10_norm_factor'], alpha=0.5, density=True, label='Noise', bins=bins)\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('Regret')\n",
    "plt.title('Out Of Distribution Regret Histogram') if is_plot_title else None\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_path, 'out_of_dist_hist.jpg'),\n",
    "            dpi=200, bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()\n",
    "print('Mean: cifar, svhn, noise: {}'.format([results_df_cifar10['log10_norm_factor'].mean(),\n",
    "                                             results_df_svhn['log10_norm_factor'].mean(),\n",
    "                                             results_df_noise['log10_norm_factor'].mean()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot entropy\n",
    "objects = ('CIFAR10', 'SVHN', 'Noise')\n",
    "y_pos = np.arange(len(objects))\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "plt.bar(y_pos - bar_width / 2, [statistic_cifar10.loc['mean entropy']['nml'],\n",
    "                                statistic_svhn.loc['mean entropy']['nml'],\n",
    "                                statistic_noise.loc['mean entropy']['nml']],\n",
    "        bar_width, alpha=0.5, color='darkorange', label='pNML')\n",
    "\n",
    "plt.bar(y_pos + bar_width / 2, [statistic_cifar10.loc['mean entropy']['erm'],\n",
    "                                statistic_svhn.loc['mean entropy']['erm'],\n",
    "                                statistic_noise.loc['mean entropy']['erm']],\n",
    "        bar_width, alpha=0.5, color='blue', label='ERM')\n",
    "\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy of out of distribution sampels') if is_plot_title else None\n",
    "plt.legend()\n",
    "plt.xlabel('Testset')\n",
    "plt.savefig(os.path.join(output_path, 'out_of_dist_entropy.jpg'),\n",
    "            dpi=200, bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('SVHN:')\n",
    "print(statistic_svhn)\n",
    "\n",
    "print()\n",
    "print('Noise:')\n",
    "print(statistic_noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluation Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import math\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "def bhattacharyya(a, b):\n",
    "    return -np.log(np.sum(np.sqrt(a * b)))\n",
    "\n",
    "\n",
    "def kl(p, q):\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    p[p == 0] = np.finfo(float).eps\n",
    "\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    q[q == 0] = np.finfo(float).eps\n",
    "    return np.sum(np.where(p > np.finfo(float).eps, - p * np.log(q / p), 0))\n",
    "\n",
    "\n",
    "def kl_distance(a, b):\n",
    "    return 0.5*(kl(a, b) + kl(b, a))\n",
    "\n",
    "\n",
    "def histogram_and_smooth(data, nbins=10, sigma=1):\n",
    "    hist = np.histogram(data, bins=nbins)[0]\n",
    "    hist_smooth = gaussian_filter(hist, sigma)\n",
    "    hist_smooth_normalized = hist_smooth/np.sum(hist_smooth)\n",
    "    return hist_smooth_normalized\n",
    "\n",
    "\n",
    "def calc_p_lamb(a_distribution, b_distribution, lamb):\n",
    "    \"\"\"\n",
    "    Calc P_lamb distribution: P_lambda = a^lamb * b^(1-lamb) / Normalize\n",
    "    \"\"\"\n",
    "    p_lamb = np.power(a_distribution, lamb) * np.power(b_distribution, 1-lamb)\n",
    "    p_lamb /= np.sum(p_lamb)\n",
    "    return p_lamb\n",
    "\n",
    "\n",
    "def find_lamb_star(a_distribution, b_distribution):\n",
    "    \"\"\"\n",
    "    Find lambda^* for which D(a||P_lambda) = D(b||P_lambda) \n",
    "    \"\"\"\n",
    "    distance = []\n",
    "    lamb_list = np.flip(np.linspace(0, 1, 20))\n",
    "\n",
    "    # For each lambda calculate the Distance D(a||P_lambda) - D(b||P_lambda)\n",
    "    for lamb in lamb_list:\n",
    "        p_lamb = calc_p_lamb(a_distribution, b_distribution, lamb)\n",
    "        distance.append(kl(p_lamb, a_distribution) -\n",
    "                        kl(p_lamb, b_distribution))\n",
    "\n",
    "    # Find lambda for which the the distance is zero\n",
    "    lamb_star = np.interp(0.0, distance, lamb_list)\n",
    "\n",
    "    # Get the KL value in that lamb_star: D(a||P_lambda)\n",
    "    p_lamb_star = calc_p_lamb(a_distribution, b_distribution, lamb_star)\n",
    "    return kl(p_lamb_star, a_distribution)\n",
    "\n",
    "\n",
    "def calc_performance_in_out_dist(true_ind, score_ind):\n",
    "    \"\"\"\n",
    "    Calculate evaluation matrics\n",
    "    \"\"\"\n",
    "    score_ood = 1 - np.array(score_ind)\n",
    "    true_ood = 1 - np.array(true_ind)\n",
    "\n",
    "    true_len = np.sum(true_ind)\n",
    "    false_len = len(true_ind) - true_len\n",
    "    sample_weight = [1] * true_len + [true_len / false_len] * false_len\n",
    "\n",
    "    # AUROC\n",
    "    res_auc = roc_auc_score(true_ood, score_ood, sample_weight=sample_weight)\n",
    "\n",
    "    # AUPR-Out\n",
    "    ap_out = average_precision_score(\n",
    "        true_ood, score_ood, sample_weight=sample_weight)\n",
    "\n",
    "    # AUPR-In\n",
    "    ap_in = average_precision_score(\n",
    "        true_ind, score_ind, sample_weight=sample_weight)\n",
    "\n",
    "    # KL distance\n",
    "    score_ind = np.array(score_ind)\n",
    "    true_ind = np.array(true_ind)\n",
    "    in_hist = histogram_and_smooth(\n",
    "        score_ind[true_ind == True], nbins=20, sigma=0)\n",
    "    out_hist = histogram_and_smooth(\n",
    "        score_ind[true_ind == False], nbins=20, sigma=0)\n",
    "    kl_dist = kl_distance(in_hist, out_hist)\n",
    "\n",
    "    # Bhattacharyya distance\n",
    "    bhatt_dist = bhattacharyya(in_hist, out_hist)\n",
    "\n",
    "    # P_lambda\n",
    "    kl_in_p_lambda = find_lamb_star(in_hist, out_hist)\n",
    "\n",
    "    ood_df = pd.DataFrame({\n",
    "        # 'AUROC': [res_auc], 'AP-In': [ap_in], 'AP-Out': [ap_out],\n",
    "        'KL Divergence': [kl_dist], 'Bhattach Distance': [bhatt_dist],\n",
    "        'KL in P_lamb': [kl_in_p_lambda]\n",
    "    })\n",
    "\n",
    "    return ood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "ind_df = results_df_cifar10\n",
    "for (ooo_dataset, ood_df) in zip(['Noise', 'SVHN'], [results_df_noise, results_df_svhn]):\n",
    "    upsample_ratio = int(ind_df.shape[0] / ood_df.shape[0])\n",
    "    print('Upsample ratio: ', upsample_ratio)\n",
    "\n",
    "    # Baseline Max prob of ERM\n",
    "    y_score_ind = ind_df[['erm_' + str(x) for x in range(10)]].max(axis=1).tolist() + \\\n",
    "        ood_df[['erm_' + str(x) for x in range(10)]].max(axis=1).tolist()\n",
    "    y_true_ind = [True] * ind_df.shape[0] + [False] * ood_df.shape[0]\n",
    "    ood_df_erm_baseline = calc_performance_in_out_dist(y_true_ind, y_score_ind)\n",
    "    ood_df_erm_baseline = ood_df_erm_baseline.rename(index={0: 'Max Prob'})\n",
    "    \n",
    "    # Baseline p1/p2 of ERM\n",
    "    p1_ind = np.sort(ind_df[['erm_' + str(x) for x in range(10)]])[:,-2:][:,1]\n",
    "    p2_ind = np.sort(ind_df[['erm_' + str(x) for x in range(10)]])[:,-2:][:,0]\n",
    "    p1_p2_ind = 1-p2_ind/p1_ind #np.clip(p1_ind/p2_ind, 0, 10**6) \n",
    "    p1_ood = np.sort(ood_df[['erm_' + str(x) for x in range(10)]])[:,-2:][:,1]\n",
    "    p2_ood = np.sort(ood_df[['erm_' + str(x) for x in range(10)]])[:,-2:][:,0]\n",
    "    p1_p2_ood= 1-p2_ood/p1_ood#np.clip(p1_ood/p2_ood, 0, 10**6) \n",
    "\n",
    "\n",
    "    y_score_ind = list(p1_p2_ind) + list(p1_p2_ood)\n",
    "    y_true_ind = [True] * ind_df.shape[0] + [False] * ood_df.shape[0]\n",
    "    ood_df_erm_baseline_2 = calc_performance_in_out_dist(y_true_ind, y_score_ind)\n",
    "    ood_df_erm_baseline_2 = ood_df_erm_baseline_2.rename(index={0: '1-p2/p1'})\n",
    "\n",
    "    # Regret based\n",
    "    y_score_ind = (1.0 - ind_df['log10_norm_factor']).tolist() + \\\n",
    "                  (1.0 - ood_df['log10_norm_factor']).tolist()\n",
    "    y_true_ind = [True] * ind_df.shape[0] + [False] * ood_df.shape[0]\n",
    "\n",
    "    ood_df_ours = calc_performance_in_out_dist(y_true_ind, y_score_ind)\n",
    "    ood_df_ours = ood_df_ours.rename(index={0: 'Regret'})\n",
    "\n",
    "    # Summary\n",
    "    merged_pd = pd.concat([ood_df_erm_baseline, ood_df_erm_baseline_2, ood_df_ours])\n",
    "    print('%s:' % ooo_dataset)\n",
    "    print(merged_pd)\n",
    "    print()\n",
    "\n",
    "    # Histogram based on Ouf Of Dist confidence\n",
    "    f, axarr = plt.subplots(3, 1)\n",
    "    nbins = 20\n",
    "    axarr[0].hist(ind_df[['erm_' + str(x) for x in range(10)]\n",
    "                         ].max(axis=1),  bins=nbins, alpha=1.0, density=True, label='CIFAR10')\n",
    "    axarr[0].hist(ood_df[['erm_' + str(x) for x in range(10)]\n",
    "                         ].max(axis=1),  bins=nbins, alpha=0.5, density=True, label=ooo_dataset)\n",
    "    axarr[0].set_xlabel('Max Probabiliy')\n",
    "    axarr[0].set_ylabel('Density')\n",
    "    axarr[0].legend()\n",
    "\n",
    "    axarr[1].hist(list(p1_p2_ind), bins=nbins,\n",
    "                  alpha=1.0, density=True, label='In-Dist')\n",
    "    axarr[1].hist(list(p1_p2_ood),bins=nbins,\n",
    "                  alpha=0.5, density=True, label=ooo_dataset)\n",
    "    axarr[1].set_xlabel(r'$1-p_2 / p_1$')\n",
    "    axarr[1].set_ylabel('Density')       \n",
    "\n",
    "    axarr[2].hist(1.0 - ind_df['log10_norm_factor'], bins=nbins,\n",
    "                  alpha=1.0, density=True, label='In-Dist')\n",
    "    axarr[2].hist(1.0 - ood_df['log10_norm_factor'],bins=nbins,\n",
    "                  alpha=0.5, density=True, label=ooo_dataset)\n",
    "    axarr[2].set_xlabel('1 - Regret')\n",
    "    axarr[2].set_ylabel('Density')\n",
    "    \n",
    "    f.subplots_adjust(hspace=0.6)\n",
    "    plt.savefig(os.path.join(output_path, 'out_of_dist_detection_%s.jpg' % ooo_dataset),\n",
    "            dpi=200, bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 = np.array(ind_df[['erm_' + str(x) for x in range(10)]].max(axis=1))\n",
    "p1 = np.sort(ind_df[['erm_' + str(x) for x in range(10)]])[:,-2:][:,1]\n",
    "p2 = np.sort(ind_df[['erm_' + str(x) for x in range(10)]])[:,-2:][:,0]\n",
    "print('p1')\n",
    "print(p1)\n",
    "print('p2')\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 10**(np.arange(0,6))\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "385d370d-0d8e-4483-95d4-7e15a6617c71"
    }
   },
   "source": [
    "# Random labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "from analyze_utilities import *\n",
    "from dataset_utilities import create_cifar10_dataloaders\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "% run ./result_summary.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3157733f-949d-4bc5-a034-1b8f681f6e2a"
    }
   },
   "outputs": [],
   "source": [
    "# Count param difference between WideResnet and Resnet20\n",
    "from wide_resnet import WideResNet\n",
    "from resnet import resnet20\n",
    "\n",
    "model = WideResNet()\n",
    "wide_resnet_params = sum(p.numel() for p in model.parameters())\n",
    "model = resnet20()\n",
    "resnet20_params = sum(p.numel() for p in model.parameters())\n",
    "print('[WideResnet Resnet20]=[{} {}]'.format(\n",
    "    wide_resnet_params, resnet20_params))\n",
    "print('Ratio {}]'.format(wide_resnet_params / resnet20_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "08059a2e-be6f-4b50-b828-9d2b564f5e09"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the log normalization factor\n",
    "random_df = pd.DataFrame(columns=['nml_acc', 'erm_acc', 'genie_acc',\n",
    "                                  'log10_norm_factor',\n",
    "                                  'nml_mean_loss', 'erm_mean_loss', 'genie_mean_loss'])\n",
    "\n",
    "for (rand_prob_single, file_random) in zip(random_prob, files_random):\n",
    "    results_df, statistics_df = load_results_to_df(file_random)\n",
    "    print('Random Prob = {}, num={}'.format(\n",
    "        rand_prob_single, results_df.shape[0]))\n",
    "    random_df.loc[rand_prob_single] = [statistics_df.loc['acc']['nml'],\n",
    "                                       statistics_df.loc['acc']['erm'],\n",
    "                                       statistics_df.loc['acc']['genie'],\n",
    "                                       results_df['log10_norm_factor'].mean(),\n",
    "                                       statistics_df.loc['mean loss']['nml'],\n",
    "                                       statistics_df.loc['mean loss']['erm'],\n",
    "                                       statistics_df.loc['mean loss']['genie']]\n",
    "print('Random df:')\n",
    "random_df.transpose().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(random_df.index.values,\n",
    "         random_df['log10_norm_factor'], '--*', label='NML')\n",
    "plt.ylabel('Regret')\n",
    "plt.xlabel('Prob of random')\n",
    "plt.title('Regret Vs. Prob to be Random') if is_plot_title else None\n",
    "# plt.savefig(os.path.join(output_path, 'random_prob_regret.jpg'),\n",
    "#             dpi=200, bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "2b10e1e3-dece-45e3-af4a-14f40a70bfe2"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check noisy data\n",
    "plt.plot(random_df.index.values, random_df['erm_mean_loss'], label='ERM')\n",
    "plt.plot(random_df.index.values, random_df['nml_mean_loss'], label='pNML')\n",
    "plt.plot(random_df.index.values, random_df['genie_mean_loss'], label='Genie')\n",
    "plt.title('Loss of random labels') if is_plot_title else None\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Prob to be Random')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_path, 'random_prob_loss.jpg'), dpi=200,\n",
    "            bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()\n",
    "\n",
    "plt.plot(random_df.index.values, random_df['erm_acc'], label='ERM')\n",
    "plt.plot(random_df.index.values, random_df['nml_acc'], label='pNML')\n",
    "plt.plot(random_df.index.values, random_df['genie_acc'], label='Genie')\n",
    "plt.title('Acc of random labels') if is_plot_title else None\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Prob to be Random')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_path, 'random_prob_acc.jpg'), dpi=200,\n",
    "            bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "def smooth_graph(x, y, pow=1):\n",
    "\n",
    "    x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "    spl = make_interp_spline(x, y, k=pow)\n",
    "    y_smooth = spl(x_smooth)\n",
    "    return x_smooth, y_smooth\n",
    "\n",
    "# Check noisy data\n",
    "color = 'royalblue'\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "x, y = smooth_graph(random_df.index.values, random_df['erm_mean_loss'])\n",
    "ax1.plot(x, y, label='ERM log-loss')\n",
    "\n",
    "x, y = smooth_graph(random_df.index.values, random_df['nml_mean_loss'])\n",
    "ax1.plot(x, y, label='pNML log-loss')\n",
    "\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_ylabel('Log-loss')\n",
    "ax1.set_xlabel('Prob to be random')\n",
    "\n",
    "# # Plot\n",
    "# ax2 = ax1.twinx()\n",
    "# x, y = smooth_graph(random_df.index.values, random_df['log10_norm_factor'])\n",
    "# ax2.plot(x, y, color='indianred', label='Regret')\n",
    "# ax2.set_ylabel('Regret')\n",
    "\n",
    "# # ax2 ticks\n",
    "# l = ax1.get_ylim()\n",
    "# l2 = ax2.get_ylim()\n",
    "\n",
    "\n",
    "# def f(x): return l2[0]+(x-l[0])/(l[1]-l[0])*(l2[1]-l2[0])\n",
    "\n",
    "\n",
    "# ticks = f(ax1.get_yticks())\n",
    "# ax2.yaxis.set_major_locator(mpl.ticker.FixedLocator(ticks))\n",
    "# ax2.yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.2f'))\n",
    "\n",
    "# # Legends\n",
    "# ax1.legend(loc=(.04, .86), frameon=False)\n",
    "# ax2.legend(loc=(.04, .94), frameon=False)\n",
    "ax1.legend()\n",
    "\n",
    "plt.savefig(os.path.join(output_path, 'random_prob_regret_and_loss.jpg'), dpi=200,\n",
    "            bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twice Universality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "from analyze_utilities import *\n",
    "from dataset_utilities import create_cifar10_dataloaders\n",
    "import pandas as pd\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "%run ./result_summary_uriya.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('load 0 layers')\n",
    "nml_0_df = result_dict_to_erm_df(load_dict_from_file_list(files_nml_2_layers))\n",
    "print('load 2 layers')\n",
    "nml_2_df = result_dict_to_nml_df(load_dict_from_file_list(files_nml_2_layers))\n",
    "print('load 7 layers')\n",
    "nml_7_df = result_dict_to_nml_df(load_dict_from_file_list(files_nml_7_layers))\n",
    "\n",
    "# Create twice df dataframe\n",
    "twice_df, idx_common = create_twice_univ_df([nml_0_df, nml_2_df, nml_7_df])\n",
    "twice_statistic_df = calc_statistic_from_df_single(twice_df).rename(columns={'statistics': 'Twice Univ'})\n",
    "\n",
    "# Print statistic of all\n",
    "twice_statistic_df = calc_statistic_from_df_single(twice_df).rename(columns={'statistics': 'Twice Univ'})\n",
    "nml_0_statistic_df = calc_statistic_from_df_single(nml_0_df.loc[idx_common]).rename(columns={'statistics':\n",
    "                                                                                                 '0 layers'})\n",
    "nml_2_statistic_df = calc_statistic_from_df_single(nml_2_df.loc[idx_common]).rename(columns={'statistics':\n",
    "                                                                                                 '2 layers'})\n",
    "nml_7_statistic_df = calc_statistic_from_df_single(nml_7_df.loc[idx_common]).rename(columns={'statistics':\n",
    "                                                                                                 '7 layers'})\n",
    "#--\n",
    "print(pd.concat([twice_statistic_df,\n",
    "                 nml_0_statistic_df,\n",
    "                 nml_2_statistic_df,\n",
    "                 nml_7_statistic_df], axis=1, join='inner').transpose())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twice_stats_df_concat = pd.DataFrame([])\n",
    "M1_stats_df_concat = pd.DataFrame([])\n",
    "M2_stats_df_concat = pd.DataFrame([])\n",
    "bagging_stats_df_concat = pd.DataFrame([])\n",
    "risk_min_stats_df_concat = pd.DataFrame([])\n",
    "\n",
    "for i in range(len(M1_list)):\n",
    "    M1_path = M1_list[i]\n",
    "    M2_path = M2_list[i]\n",
    "\n",
    "    M1 = result_dict_to_nml_df(load_dict_from_file_list(M1_path))\n",
    "    print('loaded 0 layers MNIST, {} samples'.format(M1.shape[0]))\n",
    "    M2 = result_dict_to_nml_df(load_dict_from_file_list(M2_path))\n",
    "    print('loaded 1 layers MNIST, {} samples'.format(M2.shape[0]))\n",
    "\n",
    "    # Create twice_df dataframe\n",
    "    twice_df, idx_common = create_twice_univ_df([M1, M2])\n",
    "\n",
    "    # create genie dataframe for twice_univ\n",
    "    genie_tu_df, _ = create_genie_tu_df([M1, M2])\n",
    "    \n",
    "    # create bagging dataframe\n",
    "    bagging_df, _ = create_bagging_df([M1, M2])\n",
    "    \n",
    "    # create risk minimizer dataframe\n",
    "    risk_min_df, _ = create_risk_minimizer_df([M1, M2])\n",
    "    \n",
    "    # Print statistic of all\n",
    "    twice_statistic_df = calc_statistic_from_df_single(twice_df).rename(columns={'statistics': 'Twice Univ'})\n",
    "    twice_stats_df_concat = pd.concat([twice_stats_df_concat, twice_statistic_df.transpose()])\n",
    "    \n",
    "    genie_statistic_df = calc_statistic_from_df_single(genie_tu_df).rename(columns={'statistics': 'Genie Twice Univ'})\n",
    "    counter_genie_sel_df = collections.Counter(genie_tu_df[\"selected_df\"])\n",
    "    \n",
    "    bagging_stats_df = calc_statistic_from_df_single(bagging_df).rename(columns={'statistics': 'Bagging'})\n",
    "    bagging_stats_df_concat = pd.concat([bagging_stats_df_concat, bagging_stats_df.transpose()])\n",
    "    \n",
    "    risk_min_stats_df = calc_statistic_from_df_single(risk_min_df).rename(columns={'statistics': 'Risk minimizer'})\n",
    "    risk_min_stats_df_concat = pd.concat([risk_min_stats_df_concat, risk_min_stats_df.transpose()])\n",
    "    counter_riskmin_sel_df = collections.Counter(risk_min_df[\"selected_df\"])\n",
    "    \n",
    "    M1_statistic_df = calc_statistic_from_df_single(M1.loc[idx_common]).rename(columns={'statistics':\n",
    "                                                                                                     'M1_nml'})\n",
    "    M1_stats_df_concat = pd.concat([M1_stats_df_concat, M1_statistic_df.transpose()])\n",
    "    M2_statistic_df = calc_statistic_from_df_single(M2.loc[idx_common]).rename(columns={'statistics':\n",
    "                                                                                                     'M2_nml'})\n",
    "    M2_stats_df_concat = pd.concat([M2_stats_df_concat, M2_statistic_df.transpose()])\n",
    "\n",
    "    _, statistics_df1 = load_results_to_df(M1_path, idx=idx_common )\n",
    "    statistics_df1 = statistics_df1.rename(columns={'erm': 'M1_erm', 'genie':'M1_genie'})\n",
    "    _, statistics_df2 = load_results_to_df(M2_path, idx=idx_common )\n",
    "    statistics_df2 = statistics_df2.rename(columns={'erm': 'M2_erm', 'genie':'M2_genie'})\n",
    "    # nml_2_statistic_df = calc_statistic_from_df_single(nml_2_df.loc[idx_common]).rename(columns={'statistics':\n",
    "    #                                                                                                  '2 layers'})\n",
    "    #--\n",
    "#     print('Num of common index {}'.format(twice_df.shape[0]))\n",
    "    print(pd.concat([twice_statistic_df,\n",
    "                     genie_statistic_df,\n",
    "                     M1_statistic_df,\n",
    "                     M2_statistic_df,\n",
    "                     bagging_stats_df,\n",
    "                     risk_min_stats_df,\n",
    "                     statistics_df1[['M1_erm','M1_genie']],\n",
    "                     statistics_df2[['M2_erm','M2_genie']],], axis=1, join='inner').transpose())\n",
    "    print(\"Genie selected M1 %d times \\nRisk minimizer selected M1 %d times\" % \n",
    "                              (counter_genie_sel_df[0], counter_riskmin_sel_df[0]))\n",
    "\n",
    "print()\n",
    "mean_stats = pd.concat([twice_stats_df_concat.mean(axis=0).rename('Twice Univ'),\n",
    "                       M1_stats_df_concat.mean(axis=0).rename('M1_nml'),\n",
    "                       M2_stats_df_concat.mean(axis=0).rename('M2_nml'),\n",
    "                       bagging_stats_df_concat.mean(axis=0).rename('Bagging'),\n",
    "                       risk_min_stats_df_concat.mean(axis=0).rename('Risk minimizer')], axis=1)\n",
    "print(mean_stats.transpose())                        \n",
    "# print(twice_stats_df_concat.mean(axis=0).columns)\n",
    "# print(M1_stats_df_concat.mean(axis=0).transpose())\n",
    "# print(M2_stats_df_concat.mean(axis=0).transpose())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "adversarial_df = pd.DataFrame(columns=['regret',\n",
    "                                       'erm_acc', 'nml_acc', 'genie_acc',\n",
    "                                       'erm_mean_loss', 'nml_mean_loss', 'genie_mean_loss',\n",
    "                                       'nml_std_loss', 'std_regret'])\n",
    "fig = plt.figure(figsize=(20, 6 * len(adversarial_epsilon)))\n",
    "\n",
    "# Get common indexes from all adeversarail experiments\n",
    "_, idx_common = get_testset_intersections_from_results_dfs(\n",
    "    [result_dict_to_erm_df(load_dict_from_file_list(file)) for file in files_adversarial])\n",
    "adversarial_nml_df = []\n",
    "eps = []\n",
    "for i, (epsilon_single, file_adversarial) in enumerate(zip(adversarial_epsilon, files_adversarial)):\n",
    "\n",
    "    # Load results dict into dataframe\n",
    "    results_dict = load_dict_from_file_list(file_adversarial)\n",
    "    erm_df = result_dict_to_erm_df(results_dict).loc[idx_common]\n",
    "    nml_df = result_dict_to_nml_df(results_dict).loc[idx_common]\n",
    "    genie_df = result_dict_to_genie_df(results_dict).loc[idx_common]\n",
    "    \n",
    "    adversarial_nml_df.append(nml_df)\n",
    "    eps.append(epsilon_single)\n",
    "\n",
    "    # Analyze statistic of single adversarial experimnet\n",
    "    statistics_erm_df = calc_statistic_from_df_single(erm_df)\n",
    "    statistics_nml_df = calc_statistic_from_df_single(nml_df)\n",
    "    statistics_genie_df = calc_statistic_from_df_single(genie_df)\n",
    "\n",
    "    print('epsilon = {}, num={}'.format(epsilon_single, nml_df.shape[0]))\n",
    "    adversarial_df.loc[epsilon_single] = [nml_df['log10_norm_factor'].mean(),\n",
    "                                          statistics_erm_df.loc['acc'][0],\n",
    "                                          statistics_nml_df.loc['acc'][0],\n",
    "                                          statistics_genie_df.loc['acc'][0],\n",
    "                                          statistics_erm_df.loc['mean loss'][0],\n",
    "                                          statistics_nml_df.loc['mean loss'][0],\n",
    "                                          statistics_genie_df.loc['mean loss'][0],\n",
    "                                          statistics_nml_df.loc['std loss'][0],\n",
    "                                          nml_df['log10_norm_factor'].std()]\n",
    "    # Plot the image\n",
    "#     g = sns.JointGrid(x=\"log10_norm_factor\", y=\"loss\", data=nml_df)\n",
    "#     g.plot_marginals(sns.kdeplot, shade=True, color='red')\n",
    "#     g.plot_joint(plt.hist2d, bins=[100, 100],  # norm=mpl.colors.SymLogNorm(0.1),\n",
    "#                  cmin=1, cmap=plt.cm.Reds)\n",
    "#     g.ax_joint.grid(True)\n",
    "#     g.ax_joint.set_ylabel('Log-loss')\n",
    "#     g.ax_joint.set_xlabel('Regret, $\\epsilon$={}'.format(epsilon_single))\n",
    "#     # make new ax object for the cbar\n",
    "#     plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "#     cbar_ax = g.fig.add_axes([.82, .2, .05, .5])  # x, y, width, height\n",
    "#     plt.colorbar(cax=cbar_ax).set_label(label='Count')\n",
    "#     cbar_ax.tick_params(labelsize=12)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "print('Adversarial dataframe: Performances\\Epsilon')\n",
    "adversarial_df = adversarial_df.iloc[::-1]\n",
    "adversarial_df.transpose().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "\n",
    "\n",
    "def smooth_graph(x, y, pow=1):\n",
    "\n",
    "    x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "    spl = make_interp_spline(x, y, k=pow)\n",
    "    y_smooth = spl(x_smooth)\n",
    "    return x_smooth, y_smooth\n",
    "\n",
    "\n",
    "# Check noisy data\n",
    "color = 'royalblue'\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "x, y = smooth_graph(adversarial_df.index.values,\n",
    "                    adversarial_df['erm_mean_loss'])\n",
    "ax1.plot(x, y, label='ERM log-loss')\n",
    "\n",
    "x, y = smooth_graph(adversarial_df.index.values,\n",
    "                    adversarial_df['nml_mean_loss'])\n",
    "ax1.plot(x, y, label='pNML log-loss')\n",
    "\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_ylabel('Log-loss')\n",
    "ax1.set_xlabel('$\\epsilon$')\n",
    "ax1.set_xscale('log',  basex=10)\n",
    "for axis in [ax1.xaxis, ax1.yaxis]:\n",
    "    formatter = ScalarFormatter()\n",
    "    formatter.set_scientific(False)\n",
    "    axis.set_major_formatter(formatter)\n",
    "ax1.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "\n",
    "# # Plot\n",
    "# ax2 = ax1.twinx()\n",
    "# x, y = smooth_graph(adversarial_df.index.values, adversarial_df['regret'])\n",
    "# ax2.plot(x, y, color='indianred', label='Regret')\n",
    "# ax2.set_ylabel('Regret')\n",
    "\n",
    "# # ax2 ticks\n",
    "# l = ax1.get_ylim()\n",
    "# l2 = ax2.get_ylim()\n",
    "\n",
    "\n",
    "# def f(x): return l2[0]+(x-l[0])/(l[1]-l[0])*(l2[1]-l2[0])\n",
    "\n",
    "\n",
    "# ticks = f(ax1.get_yticks())\n",
    "# ax2.yaxis.set_major_locator(mpl.ticker.FixedLocator(ticks))\n",
    "# ax2.yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.2f'))\n",
    "\n",
    "# # Legends\n",
    "# ax1.legend(loc=(.04, .835), frameon=False)\n",
    "# ax2.legend(loc=(.04, .925), frameon=False)\n",
    "ax1.legend()\n",
    "plt.savefig(os.path.join(output_path, 'epsilon_regret_and_loss.jpg'), dpi=200,\n",
    "            bbox_inches=plt.tight_layout()) if is_save_fig else None\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_df = adversarial_nml_df[-1] # get last member in the list. it is epsilon=0\n",
    "\n",
    "\n",
    "for (ooo_dataset, ooo_df) in zip(eps, adversarial_nml_df):\n",
    "    upsample_ratio = int(ind_df.shape[0] / ooo_df.shape[0])\n",
    "    print('Upsample ratio: ', upsample_ratio)\n",
    "\n",
    "\n",
    "    # Regret based\n",
    "    y_score_ind = (1.0 - ind_df['log10_norm_factor']).tolist() + \\\n",
    "                  (1.0 - ooo_df['log10_norm_factor']).tolist()\n",
    "    y_true_ind = [True] * ind_df.shape[0] + [False] * ooo_df.shape[0]\n",
    "\n",
    "    ood_df_ours = calc_performance_in_out_dist(y_true_ind, y_score_ind)\n",
    "    ood_df_ours = ood_df_ours.rename(index={0: 'Regret'})\n",
    "\n",
    "    # Summary\n",
    "    merged_pd =  ood_df_ours #pd.concat([ood_df_erm_baseline, ood_df_ours])\n",
    "    print('%s:' % ooo_dataset)\n",
    "    print(merged_pd.round(2))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a348d338-f6f4-465f-8ade-5f618c56d94d"
    }
   },
   "source": [
    "# Visualize False classified\n",
    "Visaulaize the image of the false classified by the ERM and NML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check when erm and nml are not agree\n",
    "disagree = np.logical_not(\n",
    "    np.logical_and(np.array(result_df['nml_is_correct']), np.array(np.array(result_df['erm_is_correct']))))\n",
    "disagree_indxes = np.array(result_df.index.values)[disagree == True].astype(np.int).tolist()\n",
    "print(disagree_indxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3ef62508-a86e-42b1-b839-731b77a8f810"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Given a dict an idx, visualize ERM and NMl with prob of each. along with ground truth\n",
    "\n",
    "# Inputs\n",
    "results_dict = load_dict_from_file_list(files_nml_2_layers)\n",
    "dict_idxes = [158, 384, 456]  #disagree_indxes # [245, 246]\n",
    "\n",
    "# Initialize dataset and plots\n",
    "fig = plt.figure(figsize=(20, 6 * len(dict_idxes)))\n",
    "trainloader, testloader, classes = create_cifar10_dataloaders('../data', 1, 1)\n",
    "\n",
    "# Loop on dict indxes\n",
    "for iter_idx, dict_idx in enumerate(dict_idxes):\n",
    "    prob_nml, true_label, predicted_label, prob_erm = extract_probabilities_list(results_dict[str(dict_idx)])\n",
    "    prob_nml, normalization_factor = execute_normalize_prob(prob_nml)\n",
    "\n",
    "    # Extract class names\n",
    "    class_predict_nml = classes[np.argmax(prob_nml)]\n",
    "    class_predict_erm = classes[np.argmax(prob_erm)]\n",
    "    class_predict_gt = classes[true_label]\n",
    "    # Extract image\n",
    "    data = testloader.dataset.test_data[dict_idx]\n",
    "\n",
    "    # Plot the image\n",
    "    ax = fig.add_subplot(len(dict_idxes), 1, iter_idx + 1)\n",
    "    ax.imshow(data)\n",
    "    ax.set_title('[NML ERM True] = Label: {} \\n [NML ERM] Prob: {}'\n",
    "                 .format([class_predict_nml, class_predict_erm, class_predict_gt],\n",
    "                         np.round([prob_nml[np.argmax(prob_nml)], prob_erm[np.argmax(prob_erm)]], 3)))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
